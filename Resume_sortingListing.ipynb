{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0ctKmDIHKQq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df=pd.read_csv(\"/content/UpdatedResumeDataSet.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "Yq_913yEIAnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "4gmJjYPKIqae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Category'].value_counts()"
      ],
      "metadata": {
        "id": "FJiAIlkmJC-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df['Category'])"
      ],
      "metadata": {
        "id": "t_0kw6hYJHFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lables=df['Category'].unique"
      ],
      "metadata": {
        "id": "bo2zywHHJrlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count=df['Category'].value_counts"
      ],
      "metadata": {
        "id": "s5CIV4WbJ4iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels,count)"
      ],
      "metadata": {
        "id": "SqtjSs7NJ5xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts = df['Category'].value_counts()\n",
        "labels = df['Category'].unique()\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "plt.pie(counts,labels=labels,autopct='%1.1f%%',shadow=True, colors=plt.cm.plasma(np.linspace(0,1,3)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WPWLBZUTKCK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Category Distribution:\")\n",
        "print(df['Category'].value_counts())\n",
        "\n",
        "# Get the largest category size (i.e., the category with the maximum number of entries)\n",
        "max_size = df['Category'].value_counts().max()\n",
        "\n",
        "# Perform oversampling\n",
        "balanced_df = df.groupby('Category').apply(lambda x: x.sample(max_size, replace=True)).reset_index(drop=True)\n",
        "\n",
        "# Shuffle the dataset to avoid any order bias\n",
        "df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Check the balanced category distribution\n",
        "print(\"\\nBalanced Category Distribution (After Oversampling):\")\n",
        "print(df['Category'].value_counts())"
      ],
      "metadata": {
        "id": "UZy_FuwTNBSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "def cleanResume(txt):\n",
        "  cleanTxt=re.sub('https\\S+\\s',' ',txt)\n",
        "  cleanTxt=re.sub('@\\S+',' ',cleanTxt)\n",
        "  cleanTxt=re.sub('#\\S+',' ',cleanTxt)\n",
        "  cleanTxt = re.sub('RT|cc', ' ', cleanTxt)\n",
        "  cleanTxt = re.sub('#\\S+\\s', ' ', cleanTxt)\n",
        "  cleanTxt = re.sub('@\\S+', '  ', cleanTxt)\n",
        "  cleanTxt = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', cleanTxt)\n",
        "  cleanTxt = re.sub(r'[^\\x00-\\x7f]', ' ', cleanTxt)\n",
        "  cleanText = re.sub('\\s+', ' ', cleanTxt)\n",
        "  return cleanTxt"
      ],
      "metadata": {
        "id": "pLtZKT5xKg_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleanResume('my #### $ #  #noorsaeed webiste like is this http://heloword and access it @gmain.com')"
      ],
      "metadata": {
        "id": "j-B-XBcyNRFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Resume'] = df['Resume'].apply(lambda x: cleanResume(x))"
      ],
      "metadata": {
        "id": "iXcZBCnnNDgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Resume'].head()"
      ],
      "metadata": {
        "id": "thEwGCDjNxvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Words into Categorical"
      ],
      "metadata": {
        "id": "MS1G-hIgN3se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()"
      ],
      "metadata": {
        "id": "sH2I0AILNz6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le.fit(df['Category'])\n",
        "df['Category'] = le.transform(df['Category'])"
      ],
      "metadata": {
        "id": "OUMZ6H3pN3II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Category'].head()"
      ],
      "metadata": {
        "id": "gPMiXGaeN9wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Category.unique()"
      ],
      "metadata": {
        "id": "i9GcYiTiOAFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vactorization"
      ],
      "metadata": {
        "id": "D4P66FtAOFoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "tfidf.fit(df['Resume'])\n",
        "requredTaxt  = tfidf.transform(df['Resume'])"
      ],
      "metadata": {
        "id": "TCISxLZfOCLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and test Spliting of the data"
      ],
      "metadata": {
        "id": "Jo1Dud4ZOLtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "X1MKt2pQOHvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(requredTaxt, df['Category'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "nklbtXOwOLIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "CWBbF2XCORTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "dX3YNrOJOVWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now letâ€™s train the model and print the classification report:"
      ],
      "metadata": {
        "id": "UjiJPAgOOZzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "X_train = X_train.toarray() if hasattr(X_train, 'toarray') else X_train\n",
        "X_test = X_test.toarray() if hasattr(X_test, 'toarray') else X_test\n",
        "\n",
        "knn_model = OneVsRestClassifier(KNeighborsClassifier())\n",
        "knn_model.fit(X_train, y_train)\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "print(\"\\nKNeighborsClassifier Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_knn):.4f}\")\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_knn)}\")\n",
        "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_knn)}\")"
      ],
      "metadata": {
        "id": "x817irPIOW1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Train SVC\n",
        "svc_model = OneVsRestClassifier(SVC())\n",
        "svc_model.fit(X_train, y_train)\n",
        "y_pred_svc = svc_model.predict(X_test)\n",
        "print(\"\\nSVC Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svc):.4f}\")\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_svc)}\")\n",
        "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_svc)}\")"
      ],
      "metadata": {
        "id": "vtVmR_beOc4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the File"
      ],
      "metadata": {
        "id": "Bjpj9erCOqaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(tfidf,open('tfidf.pkl','wb'))\n",
        "pickle.dump(svc_model, open('clf.pkl', 'wb'))\n",
        "pickle.dump(le, open(\"encoder.pkl\",'wb'))"
      ],
      "metadata": {
        "id": "GiZURw7IOnUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction System\n"
      ],
      "metadata": {
        "id": "KeS-obgfOwwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Function to predict the category of a resume\n",
        "def pred(input_resume):\n",
        "    # Preprocess the input text (e.g., cleaning, etc.)\n",
        "    cleaned_text = cleanResume(input_resume)\n",
        "\n",
        "    # Vectorize the cleaned text using the same TF-IDF vectorizer used during training\n",
        "    vectorized_text = tfidf.transform([cleaned_text])\n",
        "\n",
        "    # Convert sparse matrix to dense\n",
        "    vectorized_text = vectorized_text.toarray()\n",
        "\n",
        "    # Prediction\n",
        "    predicted_category = svc_model.predict(vectorized_text)\n",
        "\n",
        "    # get name of predicted category\n",
        "    predicted_category_name = le.inverse_transform(predicted_category)\n",
        "\n",
        "    return predicted_category_name[0]  # Return the category name"
      ],
      "metadata": {
        "id": "ea6GPZ2vOsdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myresume = \"\"\"I am a data scientist specializing in machine\n",
        "learning, deep learning, and computer vision. With\n",
        "a strong background in mathematics, statistics,\n",
        "and programming, I am passionate about\n",
        "uncovering hidden patterns and insights in data.\n",
        "I have extensive experience in developing\n",
        "predictive models, implementing deep learning\n",
        "algorithms, and designing computer vision\n",
        "systems. My technical skills include proficiency in\n",
        "Python, Sklearn, TensorFlow, and PyTorch.\n",
        "What sets me apart is my ability to effectively\n",
        "communicate complex concepts to diverse\n",
        "audiences. I excel in translating technical insights\n",
        "into actionable recommendations that drive\n",
        "informed decision-making.\n",
        "If you're looking for a dedicated and versatile data\n",
        "scientist to collaborate on impactful projects, I am\n",
        "eager to contribute my expertise. Let's harness the\n",
        "power of data together to unlock new possibilities\n",
        "and shape a better future.\n",
        "Contact & Sources\n",
        "Email: 611noorsaeed@gmail.com\n",
        "Phone: 03442826192\n",
        "Github: https://github.com/611noorsaeed\n",
        "Linkdin: https://www.linkedin.com/in/noor-saeed654a23263/\n",
        "Blogs: https://medium.com/@611noorsaeed\n",
        "Youtube: Artificial Intelligence\n",
        "ABOUT ME\n",
        "WORK EXPERIENCE\n",
        "SKILLES\n",
        "NOOR SAEED\n",
        "LANGUAGES\n",
        "English\n",
        "Urdu\n",
        "Hindi\n",
        "I am a versatile data scientist with expertise in a wide\n",
        "range of projects, including machine learning,\n",
        "recommendation systems, deep learning, and computer\n",
        "vision. Throughout my career, I have successfully\n",
        "developed and deployed various machine learning models\n",
        "to solve complex problems and drive data-driven\n",
        "decision-making\n",
        "Machine Learnine\n",
        "Deep Learning\n",
        "Computer Vision\n",
        "Recommendation Systems\n",
        "Data Visualization\n",
        "Programming Languages (Python, SQL)\n",
        "Data Preprocessing and Feature Engineering\n",
        "Model Evaluation and Deployment\n",
        "Statistical Analysis\n",
        "Communication and Collaboration\n",
        "\"\"\"\n",
        "\n",
        "pred(myresume)"
      ],
      "metadata": {
        "id": "MR3cLqHHO7zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myresume = input()\n",
        "pred(myresume)"
      ],
      "metadata": {
        "id": "Pi48XOBiO4BN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yC7qCpq6PEk1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}